---
title: "final_data_summary"
author: "Jessica Chung /Melissa Carew"
date: "01/03/2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This final section enables data to be arranged into a final table for future analysis.

# producing final data summary

Starting from here will need the thershold list and the sample_df from Cache03
```{r}
load(here::here("i8s/cache/03.RData"))
#save(thresholds_list, file = here("cache/thresholds_list.RData"))
#saveRDS(samples_df, file = here("cache/samples_df.rds"))

# clear Global environment
#load(here::here("cache/thresholds_list.RData"))
#load(here::here("cache/samples_df.rds"))
```

# load results files from previuos steps
```{r}
g18s_lulu <- readRDS(here("18s/results/lulu/18s_lulu.rds"))
g18s_classifications <- read_qza(here("18s/results/classification/g18s_classification.qza"))
g18s_seq <- read_qza(here("18s/results/dada2/g18s_representative_sequences.qza"))

```



# check classification data for right amplicon
```{r}
g18s_classifications$data %>% head(100)
```


```{r}
# Pull out table of read counts with LULU filter applied
g18s_lulu$curated_table

#short_lulu <- data.frame(short_lulu$curated_table)
#short_class <- data.frame(short_classifications$data)
```

```{r}
# merge short_classifications with tHersholds
g18s_df <- merge(g18s_classifications$data, thresholds_list[["g18s"]], by.x="Feature.ID", by.y="feature-id")
```

```{r}
g18s_seq$data %>% head
```

```{r}
g18s_df %>% arrange(desc(max_p_identity)) %>% head(100)
```


```{r}
table(g18s_df$Taxon == "Unassigned")
```

```{r}
g18s_df %>% filter(Taxon == "Unassigned") %>% pull(max_p_identity) %>% table
```



```{r}
# for big dataset
g18s_search_results <- read_tsv(here("18s/results/classification/preliminary/g18s_vsearch.tsv"))

```

```{r}
g18s_search_results$data %>% dim
```


## Combine workflow outputs

# fix sample names

This can be changed with future feedback.  

We could use https://docs.qiime2.org/2023.5/plugins/available/feature-table/filter-features-conditionally/
if we want simple filtering, but if we want to do something complex, better to do it manually.


```{r}
reads_table <- list(g18s = g18s_lulu$curated_table)
```


```{r}
# Get sample names and groups
sample_groups <- samples_df$factor
names(sample_groups) <- samples_df$sample_name
sample_groups
```

```{r}
# Need to rename columns to get rid of the prefix X character if sample names start with a digit
if (all(! colnames(reads_table[[1]]) %in% names(sample_groups))) {
  reads_table <- lapply(reads_tableu, function(x) {
    colnames(x) <- str_remove(colnames(x), "^X")
    return(x)
  })
}

```



#Combining read classification tables for the short and right amplicons
```{r}
# rename column 1
colnames(g18s_df)[1] <- "asv_code"

# covert row headers to column and then name column 1
g18s_read_tab <- reads_table$g18s
g18s_read_tab <- rownames_to_column(g18s_read_tab, var = "asv_code")

g18s_read_tab <- g18s_read_tab %>%
  mutate(asv_code = as.character(asv_code))
# join into a singe dataframe
all_readclass_df <- left_join(g18s_read_tab, g18s_df, by = "asv_code")
```

# add in ASV sequence data
```{r}
# put sequences in a dataframe
g18s_asvseq <- data.frame(g18s_seq$data)

# covert row headers to column and then name column 1
g18s_asvseq <- rownames_to_column(g18s_asvseq, var = "asv_code")


# add amplicon information
g18s_asvseq  <- mutate(g18s_asvseq, amplicon = "g18s")


# align column names for merging
#g18s_asvseq <- g18s_asvseq %>% rename(asv_seq = g18s_seq.data)


```

```{r}
# merge ALL data into a single dataframe
final_df <- left_join(all_readclass_df, g18s_asvseq, by = "asv_code")

# remove columns without data
final_df <- na.omit(final_df)

final_df$Taxon <- gsub("k__", "", final_df$Taxon)
final_df$Taxon <- gsub("p__", "", final_df$Taxon)
final_df$Taxon <- gsub("c__", "", final_df$Taxon)
final_df$Taxon <- gsub("o__", "", final_df$Taxon)
final_df$Taxon <- gsub("f__", "", final_df$Taxon)
final_df$Taxon <- gsub("g__", "", final_df$Taxon)
final_df$Taxon <- gsub("s__", "", final_df$Taxon)

# place taxonomic data in separate columns
final_df <- separate(final_df, Taxon, into = c("kingdom", "phylum", "class", "order", "family", "genus","species"), sep = ";",  fill = "right")

# final tidy up (remove 'NA' and X from start of sample names)
final_df[is.na(final_df)] <- ""
names(final_df) <- sub("X", "", names(final_df))
head(final_df)

# save dataframe
write.csv(final_df, file = "~/git/metabarcoding_workflow/18s/results/final_data_summaryX_X_24.csv", row.names = FALSE)

```

# have not explored script beyond this point (Mel)
```{r}
# Filter the feature tables. Expect some false positives due to mis-tagging.
# If an observation is only seen in one replicate and is very low compared to other samples,
# consider it a false positive and replace the number with a zero

# Filter 1
# If the number of barcodes for a sample is only seen in one replicate and the number is below
# <threshold_absolute> observations, then remove it
threshold_absolute <- 0

# Filter 2
# Using the samples that have the largest observation of the barcode, take the average number
# from all its replicates. If the barcode is only seen in one replicate of another sample,
# if the number of barcodes is less than <threshold_relative_to_max_sample> * max_average, 
# remove it
# e.g. For barcode 1, if sample A has 3 replicates with (0, 0, 4) observations, and sample B has 3
# observations (500, 550, 450). The average of sample B is 500. If <threshold_relative_to_max_sample>
# is set to 0.01, the threshold is 5. Since sample A's single observation is less than 5, the
# observation will be removed
threshold_relative_to_max_sample <- 0.01
```

Currently applying filter 1, then filter 2 on the results after filter 1. But can be changed to do both filters independently.

```{r}
f1_filtered <- list()
for (l in names(all_tables)) {
  matrix_list <- list()
  for (g in unique(sample_groups)) {
    sample_ids <- names(sample_groups)[sample_groups == g]
    x <- all_tables[[l]][,sample_ids]
    ok1 <- x > 0
    ok2 <- x >= threshold_absolute
    # Keep ASVs if they have observations in at least two samples within a replicate group or have 
    # observations > <threshold_absolute> in one sample. Else, set observations to zero for that ASV
    # for that group
    ok_asvs <- rowSums(ok1) > 1 | rowSums(ok2) >= 1
    # Check removed ASVs that are non-zero
    # print(x[! ok_asvs,][rowSums(x[! ok_asvs,]) > 0,])
    # Set failed ASVs to zero
    x[! ok_asvs,] <- 0
    matrix_list[[g]] <- x
  }
  names(matrix_list) <- NULL
  f1_filtered[[l]] <- do.call(cbind, matrix_list)
}


# Check dimensions
sapply(f1_filtered, dim)

# Check dimensions of non-zero ASVs
sapply(f1_filtered, function(x) {x[rowSums(x) > 0,] %>% dim})
```



```{r}
f2_filtered <- list()
for (l in names(all_tables)) {
  matrix_list <- list()
  # First get mean observations for each sample group
  mean_list <- list()
  for (g in unique(sample_groups)) {
    sample_ids <- names(sample_groups)[sample_groups == g]
    x <- f1_filtered[[l]][,sample_ids]
    mean_list[[g]] <- rowMeans(f1_filtered[[l]][,sample_ids])
  }
  
  # Get the max mean observation for each ASV
  max_mean_obs <- do.call(cbind, mean_list) %>% apply(1, max)
  
  # Get the threshold
  f2_threshold <- max_mean_obs * threshold_relative_to_max_sample
  
  # If there's only a single observation in the sample group and that observation is 
  # less than <f2_threshold>, set observations to zero for that ASV in the group
  for (g in unique(sample_groups)) {
    sample_ids <- names(sample_groups)[sample_groups == g]
    x <- f1_filtered[[l]][,sample_ids]
    ok1 <- x > 0
    ok2 <- x >= f2_threshold
    ok_asvs <- rowSums(ok1) > 1 | rowSums(ok2) >= 1
    # Check removed ASVs that are non-zero
    # print(x[! ok_asvs,][rowSums(x[! ok_asvs,]) > 0,])
    # Set failed ASVs to zero
    x[! ok_asvs,] <- 0
    matrix_list[[g]] <- x
  }
  names(matrix_list) <- NULL
  f2_filtered[[l]] <- do.call(cbind, matrix_list)
}

# Check dimensions
sapply(f2_filtered, dim)

# Check dimensions of non-zero ASVs
sapply(f2_filtered, function(x) {x[rowSums(x) > 0,] %>% dim})
```






```{r}
# Sanity check ASVs that changed
diff <- lapply(names(all_tables), function(l) {
  diff <- rowMeans(all_tables[[l]] == f2_filtered[[l]]) != 1
  names(diff)[diff]
})

# e.g.
all_tables[[1]][diff[[1]],]
f2_filtered[[1]][diff[[1]],]
```



# Truncate Taxonomy?

```
Generally, any DNA barcode sequence match to the above 97% would be considered a species level match. At present, I truncate matches of >96%->95% to genus, <95% to >92% to family
```



